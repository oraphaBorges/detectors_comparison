{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detectors Comparison\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Detectors Comparison é um software coletor de estatísticas de algoritmos de detecção e extração de keypoints em fotografias turisticas.\n",
    "Os dados estatísticos coletados são utilizados para avaliar o desempenho e precisão dos algoritmos: [ORB](), [BRISK](), [AKAZE](), [SIFT]() e [SURF]() em relação ao tempo de execução, quantidade de keypoints, quantidade de matches e porcentagem de acerto. A comparação é dividida em quatro categorias/casos/situações de pares de fotos: retratando o mesmo objeto na mesma escala, o mesmo objeto em escalas diferentes, objetos diferentes na mesma escala e objetos diferentes em escalas diferentes. Todos os pares de imagens se encontram relativamente no mesmo ângulo de visão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizarmos a tarefa proposta utilizamos como biblioteca principal a [OpenCV](), a qual fornece os algoritmos comparados. A demais bibliotecas ([NumPy](), [SciPy](), [SymPy](), [Time]() e [Matplotlib]()) funcionam como auxiliáres para a coleta de dados. Os dados, por sua vez, são salvos pelo [SQLite 3]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sympy import Point, Line\n",
    "from time import time, strftime\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processo de coleta de dados\n",
    "\n",
    "A etapa principal do processo de coleta de cados consiste em:\n",
    "\n",
    "+ Encontrar os Keypoints;\n",
    "+ Encontrar os Matches através de uma busca completa;\n",
    "+ Avaliar a taxa de acerto;\n",
    "+ Calcular os ângulos entre as retas que passam pelo centro da imagem e cada keypoint com a reta horizontal (que passa pelo centro da imagem e o pixel mais à direita de mesma altura/coordenada y);\n",
    "+ Calcular as diferenças entre os ângulos dos keypoints;\n",
    "+ Calcular as razões entre as distâncias dos centros das imagens e seus keypoints, que chamamos de escala entre as imagens;\n",
    "+ Calcular as médias e desvios padrão dos ângulos dos keypoints e das escalas;\n",
    "+ Rotacionar a imagem da esquerda com a média dos ângulos dos keypoints;\n",
    "+ Ampliar a imagem da esquerda com a escala;\n",
    "+ Rencontrar os novos keypoints e matches;\n",
    "+ Reavaliar a taxa de acerto;\n",
    "+ Remover os falsos Matches:\n",
    "    + Filtrar os ângulos e escalas menores que a média menos um desvio padrão ou maiores que a média mais um desvio padrão.\n",
    "+ Recalcular as médias e os desvios padrão dos ângulos dos keypoints e das escalas;\n",
    "+ Reaplicar a rotação e a ampliação com os novos valores de média;\n",
    "+ Rencontrar os novos keypoints e matches;\n",
    "+ Reavaliar a taxa de acerto;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_OF_PAIRS = 1\n",
    "TABLE_NAME = 'datas_{}'.format(strftime('%y%m%d_%H%M%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finds the image's center\n",
    "def image_center(image):\n",
    "    return Point(image.shape[1] / 2, image.shape[0] / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finds the angles between the horizontal axis\n",
    "# and the lines passing through the image center\n",
    "# and each keypoint\n",
    "def g_find_kp_angles(image, kps):\n",
    "    angles = []\n",
    "    center = image_center(image)\n",
    "    h_axis = Line(center, center.translate(center.x))\n",
    "    for kp in kps:\n",
    "        p = Point(kp.pt[0], kp.pt[1])\n",
    "        kp_line = Line(center, p)\n",
    "        angles.append(float(h_axis.angle_between(kp_line)))\n",
    "    return angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def angles_dif(angles_img1, angles_img2, matches):\n",
    "    dif = []\n",
    "    for match in matches :\n",
    "        dif.append(angles_img1[match.queryIdx] - angles_img2[match.trainIdx])\n",
    "\n",
    "    return dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_fake_matches(matches,dif_angles,angles_mean,angles_std,scales,scale_mean,scale_std):\n",
    "    new_scales,new_dif_angles = [],[]\n",
    "    for i in range(len(matches)):\n",
    "        if dif_angles[i] < angles_mean + angles_std and dif_angles[i] > angles_mean - angles_std and scales[i] < scale_mean + scale_std and scales[i] > angles_mean - scale_std:\n",
    "            new_scales.append(scales[i])\n",
    "            new_dif_angles.append(dif_angles[i])\n",
    "    return new_dif_angles,new_scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finds the Key's points Angles\n",
    "def find_kp_angles(kp1, kp2, matches, center1, center2):\n",
    "    central_line = Line(center1, center2.translate(2 * center2.x))\n",
    "    angles = []\n",
    "    for match in matches:\n",
    "        p1 = Point(kp1[match.queryIdx].pt[0], kp1[match.queryIdx].pt[1])\n",
    "        p2 = Point(kp2[match.trainIdx].pt[0], kp2[match.trainIdx].pt[1])\n",
    "        match_line = Line(p1, p2.translate(2 * center2.x))\n",
    "        angles.append(float(central_line.angle_between(match_line)))\n",
    "    return angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def g_find_scale(image, kps):\n",
    "    scale = []\n",
    "    center = image_center(image)\n",
    "    for kp in kps:\n",
    "        p = Point(kp.pt[0], kp.pt[1])\n",
    "        d = center.distance(p)\n",
    "        scale.append(d)\n",
    "    return scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finds the ratio of the keypoints scale between images\n",
    "def find_scale_ratios(img1, kp1, img2, kp2, matches):\n",
    "    ratios = []\n",
    "    scale1 = g_find_scale(img1, kp1)\n",
    "    scale2 = g_find_scale(img2, kp2)\n",
    "    for match in matches:\n",
    "        # scale list preserves the ordering from keypoints list\n",
    "        d1 = scale1[match.queryIdx]\n",
    "        d2 = scale2[match.trainIdx]\n",
    "        ratios.append(float(d1 / d2))\n",
    "    return ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finds the Scale between images\n",
    "def find_scale(kp1, kp2, matches, center1, center2):\n",
    "    scale = []\n",
    "    for match in matches:\n",
    "        p1 = Point(kp1[match.queryIdx].pt[0], kp1[match.queryIdx].pt[1])\n",
    "        p2 = Point(kp2[match.trainIdx].pt[0], kp2[match.trainIdx].pt[1])\n",
    "        d1 = center1.distance(p1)\n",
    "        d2 = center2.distance(p2)\n",
    "        scale.append(float(d1 / d2))\n",
    "    return scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def affine_trans(img,angles,scale):\n",
    "    center = image_center(img)\n",
    "    m = cv2.getRotationMatrix2D((center.y, center.x), angles, scale)\n",
    "    return cv2.warpAffine(img, m, (img.shape[1],img.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save(conn,cursor,values):\n",
    "    cursor.execute(\"\"\"\n",
    "      INSERT INTO {} (kp1,kp2,matches,time,anglesMean,anglesSD,scaleMean,scaleSD,technique,situation,pathImg1,pathImg2,phase)\n",
    "      VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?)\n",
    "      \"\"\".format(TABLE_NAME), values)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ploting_image_pair(left,right):\n",
    "    fig = plt.figure()\n",
    "    fig.add_subplot(1,2,1)\n",
    "    plt.imshow(left)\n",
    "    fig.add_subplot(1,2,2)\n",
    "    plt.imshow(right)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getStats(method,img1, img2):\n",
    "    timeI = time()\n",
    "    # find the keypoints and descriptors with ORB\n",
    "    kp1, des1 = method.detectAndCompute(img1, None)\n",
    "    kp2, des2 = method.detectAndCompute(img2, None)\n",
    "    timeF = time()\n",
    "\n",
    "    # create BFMatcher object\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "\n",
    "    # Match descriptors. (query,train)\n",
    "    matches = bf.match(des1, des2)\n",
    "\n",
    "    # Sort them in the order of their distance.\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    return [kp1,kp2, matches, timeF - timeI]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_values(img1,img2,method,name,case,pair):\n",
    "    values = getStats(method,img1,img2)\n",
    "    kp1,kp2,matches = values[0],values[1],values[2]\n",
    "    values[0],values[1],values[2] = len(kp1),len(kp2),len(matches)\n",
    "\n",
    "    angles_img1 = g_find_kp_angles(img1,kp1)\n",
    "    angles_img2 = g_find_kp_angles(img2,kp2)\n",
    "    angles_dif = angles_dif(angles_img1,angles_img2,matches)\n",
    "    scales =  find_scale_ratios(img1, kp1, img2, kp2, matches)\n",
    "\n",
    "    angles_mean = stats.tstd(angles_dif)\n",
    "    angles_std = stats.tstd(angles_dif)\n",
    "\n",
    "    scale_mean = stats.tmean(scales)\n",
    "    scale_std = stats.tstd(scales)\n",
    "\n",
    "    values.append(angles_mean)\n",
    "    values.append(angles_std)\n",
    "    values.append(scale_mean)\n",
    "    values.append(scale_std)\n",
    "    values.append(name)\n",
    "    values.append(case)\n",
    "    values.append('{}a.jpg'.format(pair))\n",
    "    values.append('{}b.jpg'.format(pair))\n",
    "\n",
    "    return angles_dif,scales,matches, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    executeTimeI = time()\n",
    "    conn = sqlite3.connect('banco.db')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\n",
    "      \"\"\"CREATE TABLE {} (\n",
    "            technique TEXT,\n",
    "            situation TEXT,\n",
    "            kp1 INTEGER,\n",
    "            kp2 INTEGER,\n",
    "            matches INTEGER,\n",
    "            time FLOAT,\n",
    "            anglesMean FLOAT,\n",
    "            anglesSD FLOAT,\n",
    "            scaleMean FLOAT,\n",
    "            scaleSD FLOAT,\n",
    "            pathImg1 TEXT,\n",
    "            pathImg2 TEXT,\n",
    "            phase INTEGER\n",
    "      );\"\"\".format(TABLE_NAME)\n",
    "    )\n",
    "\n",
    "    # Initiate detectors\n",
    "    # SIFT = cv2.xfeatures2d.SIFT_create()\n",
    "    # SURF = cv2.xfeatures2d.SURF_create()\n",
    "    ORB = cv2.ORB.create()\n",
    "    # # KAZE = cv2.KAZE.create()\n",
    "    # AKAZE = cv2.AKAZE.create()\n",
    "    # BRISK = cv2.BRISK.create()\n",
    "\n",
    "    methods = {\n",
    "        # 'SIFT': SIFT,\n",
    "        # 'SURF': SURF,\n",
    "        'ORB': ORB,\n",
    "        # 'KAZE': KAZE,\n",
    "        # 'AKAZE': AKAZE,\n",
    "        # 'BRISK': BRISK\n",
    "    }\n",
    "\n",
    "    cases = [\n",
    "        'Same Object, Same Scale',\n",
    "        # 'Same Object, Different Scale',\n",
    "        # 'Different Object, Same Scale',\n",
    "        # 'Different Object, Different Scale',\n",
    "    ]\n",
    "\n",
    "    for case in cases:\n",
    "      print(case)\n",
    "      for pair in range(NUM_OF_PAIRS):\n",
    "        print('Pair {}/{}'.format(pair + 1, NUM_OF_PAIRS))\n",
    "        img1 = cv2.imread('photos/{}/{}a.jpg'.format(case,pair),0)\n",
    "        img2 = cv2.imread('photos/{}/{}b.jpg'.format(case,pair),0)\n",
    "        for name, method in methods.items():\n",
    "          print(name)\n",
    "          print(\"Phase One: Compares unaltered images\")\n",
    "          angles_dif,scales,matches,original_values = prep_values(img1,img2,method,name,case,pair)\n",
    "          original_values.append(1)\n",
    "          save(conn, cursor,tuple(original_values))\n",
    "\n",
    "          print('Phase two: Calculates the transformation')\n",
    "          angles_mean = original_values[4]\n",
    "          scale_mean = original_values[6]\n",
    "          dst = gmt.affine_trans(img1,angles_mean,scale_mean)\n",
    "          ploting_image_pair(dst,img2)\n",
    "          _,_,_,values = prep_values(dst,img2,method,name,case,pair)\n",
    "          values.append(2)\n",
    "\n",
    "          save(conn, cursor,tuple(values))\n",
    "\n",
    "          print(\"Phase three: Removes fake matches\")\n",
    "          angles_mean = original_values[4]\n",
    "          angles_std = original_values[5]\n",
    "          scale_mean = original_values[6]\n",
    "          scale_std = original_values[7]\n",
    "\n",
    "          angles_dif,scales = gmt.remove_fake_matches(matches,angles_dif,angles_mean,angles_std,scales,scale_mean,scale_std)\n",
    "\n",
    "          angles_mean = stats.tstd(angles_dif)\n",
    "          angles_std = stats.tstd(angles_dif)\n",
    "          scale_mean = stats.tmean(scales)\n",
    "          scale_std = stats.tstd(scales)\n",
    "\n",
    "          dst = gmt.affine_trans(img1,angles_mean,scale_mean)\n",
    "          ploting_image_pair(dst,img2)\n",
    "\n",
    "          _,_,_,values = prep_values(dst,img2,method,name,case,pair)\n",
    "\n",
    "          values.append(3)\n",
    "\n",
    "          save(conn, cursor,tuple(values))\n",
    "\n",
    "        del img1\n",
    "        del img2\n",
    "    conn.close()\n",
    "    executeTimeF = time()\n",
    "    print('Test executed in {} seconds'.format(executeTimeF-executeTimeI))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same Object, Same Scale\n",
      "Pair 1/1\n",
      "ORB\n",
      "Phase One: Compares unaltered images\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'angles_dif' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-732e713bc564>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-47-22097a2da2ff>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m           \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m           \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Phase One: Compares unaltered images\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m           \u001b[0mangles_dif\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscales\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moriginal_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m           \u001b[0moriginal_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m           \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-5b3b09cfd2df>\u001b[0m in \u001b[0;36mprep_values\u001b[0;34m(img1, img2, method, name, case, pair)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mangles_img1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_find_kp_angles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mangles_img2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_find_kp_angles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mangles_dif\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mangles_dif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangles_img1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mangles_img2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mscales\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mfind_scale_ratios\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'angles_dif' referenced before assignment"
     ]
    }
   ],
   "source": [
    "if(__name__ == '__main__'):\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
